{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Blaine\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True  # dynamically grow the memory used on the GPU\n",
    "config.log_device_placement = True  # to log device placement (on which device the operation ran)\n",
    "                                    # (nothing gets printed in Jupyter, only if you run it standalone)\n",
    "sess = tf.Session(config=config)\n",
    "set_session(sess)  # set this TensorFlow session as the default session for Keras\n",
    "\n",
    "import librosa\n",
    "import os as os\n",
    "from scipy.misc import comb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import to_categorical\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"./large_files/audio/\"  \n",
    "\n",
    "\n",
    "def get_labels(path=DATA_PATH):\n",
    "    labels = os.listdir(path)\n",
    "    label_indices = np.arange(0, len(labels))\n",
    "    return labels, label_indices, to_categorical(label_indices)\n",
    "# Get available labels\n",
    "labels, indices, _ = get_labels(DATA_PATH)\n",
    "\n",
    "\n",
    "# Getting first arrays\n",
    "X = np.load(labels[0] + '.npy')\n",
    "y = np.zeros(X.shape[0])\n",
    "\n",
    "# Append all of the dataset into one single array, same goes for y\n",
    "for i, label in enumerate(labels[1:]):\n",
    "    x = np.load(label + '.npy')\n",
    "    X = np.vstack((X, x))\n",
    "    y = np.append(y, np.full(x.shape[0], fill_value= (i + 1)))\n",
    "\n",
    "assert X.shape[0] == len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "\n",
    "# Second dimension of the feature is dim2\n",
    "feature_dim_2 = 11\n",
    "\n",
    "# # Feature dimension\n",
    "feature_dim_1 = 20\n",
    "channel = 1\n",
    "epochs = 20\n",
    "batch_size = 50\n",
    "verbose = 2\n",
    "num_classes = 30\n",
    "\n",
    "# Reshaping to perform 2D convolution\n",
    "X = X.reshape(X.shape[0], feature_dim_1, feature_dim_2, channel)\n",
    "\n",
    "\n",
    "y_hot = to_categorical(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'numpy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-6d282094befb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[1;31m# fix random seed for reproducibility\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[0mseed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m7\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 48\u001b[1;33m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'numpy' is not defined"
     ]
    }
   ],
   "source": [
    "def get_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, kernel_size=(2, 2), activation='relu', input_shape=(feature_dim_1, feature_dim_2, channel)))\n",
    "    model.add(Conv2D(48, kernel_size=(2, 2), activation='relu'))\n",
    "    model.add(Conv2D(120, kernel_size=(2, 2), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "                  optimizer=keras.optimizers.Adadelta(),\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def get_larger_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(64, kernel_size=(2, 2), activation='relu', input_shape=(feature_dim_1, feature_dim_2, channel)))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(96, kernel_size=(2, 2), activation='relu'))\n",
    "    model.add(Conv2D(240, kernel_size=(2, 2), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "                  optimizer=keras.optimizers.Adadelta(),\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Predicts one sample\n",
    "def predict(filepath, model):\n",
    "    sample = wav2mfcc(filepath)\n",
    "    sample_reshaped = sample.reshape(1, feature_dim_1, feature_dim_2, channel)\n",
    "    return get_labels()[0][\n",
    "            np.argmax(model.predict(sample_reshaped))\n",
    "    ]\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "numpy.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# k=2\n",
    "# num_val_samples = len(X) // k\n",
    "# all_scores = []\n",
    "\n",
    "\n",
    "# for i in range(k):\n",
    "#     print('processing fold #', i)\n",
    "#     # Prepare the validation data: data from partition # k\n",
    "#     val_data = X[i * num_val_samples: (i + 1) * num_val_samples]\n",
    "#     val_targets = y_hot[i * num_val_samples: (i + 1) * num_val_samples]\n",
    "\n",
    "#     # Prepare the training data: data from all other partitions\n",
    "#     partial_train_data = np.concatenate(\n",
    "#         [X[:i * num_val_samples],\n",
    "#          X[(i + 1) * num_val_samples:]],\n",
    "#         axis=0)\n",
    "#     partial_train_targets = np.concatenate(\n",
    "#         [y_hot[:i * num_val_samples],\n",
    "#          y_hot[(i + 1) * num_val_samples:]],\n",
    "#         axis=0)\n",
    "\n",
    "model = get_model()\n",
    "model.fit(X, y_hot,\n",
    "batch_size=batch_size, \n",
    "epochs=epochs, \n",
    "verbose=verbose         )\n",
    "#     val_mse, val_mae = model.evaluate(val_data, val_targets, verbose=0)\n",
    "#     all_scores.append(val_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      " - 17s - loss: 2.4936 - acc: 0.2735\n",
      "Epoch 2/20\n",
      " - 10s - loss: 1.5122 - acc: 0.5557\n",
      "Epoch 3/20\n",
      " - 10s - loss: 1.2750 - acc: 0.6302\n",
      "Epoch 4/20\n",
      " - 10s - loss: 1.1555 - acc: 0.6642\n",
      "Epoch 5/20\n",
      " - 10s - loss: 1.0790 - acc: 0.6862\n",
      "Epoch 6/20\n",
      " - 10s - loss: 1.0377 - acc: 0.6979\n",
      "Epoch 7/20\n",
      " - 10s - loss: 0.9899 - acc: 0.7138\n",
      "Epoch 8/20\n",
      " - 10s - loss: 0.9640 - acc: 0.7214\n",
      "Epoch 9/20\n",
      " - 10s - loss: 0.9412 - acc: 0.7312\n",
      "Epoch 10/20\n",
      " - 10s - loss: 0.9088 - acc: 0.7394\n",
      "Epoch 11/20\n",
      " - 10s - loss: 0.9010 - acc: 0.7434\n",
      "Epoch 12/20\n",
      " - 10s - loss: 0.8848 - acc: 0.7474\n",
      "Epoch 13/20\n",
      " - 10s - loss: 0.8694 - acc: 0.7509\n",
      "Epoch 14/20\n",
      " - 11s - loss: 0.8559 - acc: 0.7560\n",
      "Epoch 15/20\n",
      " - 10s - loss: 0.8517 - acc: 0.7583\n",
      "Epoch 16/20\n",
      " - 10s - loss: 0.8545 - acc: 0.7567\n",
      "Epoch 17/20\n",
      " - 10s - loss: 0.8487 - acc: 0.7603\n",
      "Epoch 18/20\n",
      " - 11s - loss: 0.8426 - acc: 0.7634\n",
      "Epoch 19/20\n",
      " - 11s - loss: 0.8376 - acc: 0.7628\n",
      "Epoch 20/20\n",
      " - 11s - loss: 0.8362 - acc: 0.7651\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x152488cb4e0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_larger_model()\n",
    "model.fit(X, y_hot,\n",
    "batch_size=batch_size, \n",
    "epochs=epochs, \n",
    "verbose=verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('good_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
